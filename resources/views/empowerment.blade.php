@extends('layouts.app')

@section('content')
    <h1>„Programmierte Ungerechtigkeit“: Laut einer neuen Doku werden Frauen tagtäglich von der Technik diskriminiert!</h1>
    <p class="card-text">
        <b>Ungerechtigkeit</b> zieht sich durch unseren Alltag und ist eigentlich überall. Sie macht uns wütend, raubt uns
        Kraft,
        aber nicht immer bemerken wir sie. Denn nicht nur in der realen Welt existieren Ungerechtigkeiten, sondern auch in
        der digitalen – sie stecken in unserer Technik, in den verborgenen Codes, die sie steuern. Egal, ob wir einen neuen
        Job suchen, einen Kredit abschließen oder uns einfach auf einer sozialen Plattform austauschen wollen: Algorithmen
        verstärken Vorurteile und wirken diskriminierend auf <b>Frauen</b> und Minderheiten.
    <p>

    <p class="card-text">Über diese digitale Ausgrenzung wird in der neuen Doku <b>„Programmierte Ungerechtigkeit“ </b> Es
        ist die erste
        Folge der Reihe „Digital Empire“ in der ZDF-Mediathek. Darin erzählen Menschen von der Diskriminierung, die sie
        erfahren haben – im realen Leben und in der digitalen Welt. Außerdem erklären Expert:innen, was hinter der digitalen
        Diskriminierung steckt.</p>
    <h4><strong>Programmierte Ungerechtigkeit: Warum ist Technik sexistisch?</strong></h4>
    <p class="card-text">Schuld an der <b>digitalen Diskriminierung</b> von Frauen sind Algorithmen oder besser: diejenigen,
        die Algorithmen
        programmieren. Ein Algorithmus ist eine Art Gebrauchsanweisung, die einem Computer sagt, was er machen soll, um eine
        bestimmte Aufgabe zu bewältigen. Diese Regeln werden hauptsächlich von Männern geschrieben – laut der ZDF-Doku sind
        nur
        16 Prozent der Programmierer:innen in diesem Bereich weiblich. Weil aber diese Regeln nie unsere diverse und
        komplexe
        Welt abbilden können, werden Algorithmen so konzipiert, dass sie sich weiterbilden können. Sie lernen aus Daten und
        entwickeln daraus Muster. Das ist künstliche Intelligenz. Leider orientieren sich allerdings die meisten Datensätze
        an
        Männern – weil diese nun mal als Standard gelten.</p>

    <p class="card-text">So glaubt Sandra Wachter, Juristin und Professorin an der Universität in Oxford, Algorithmen seien
        der Spiegel
        unserer
        Gesellschaft: „Sehr oft wird Technik entwickelt, die dann diejenigen, die sozial eh schon schwach sind, noch mehr
        belastet.“ So müssten <b>Frauen</b> online die gleichen Hürden überwinden wie im wahren Leben – auch in den gleichen
        Bereichen:
        Arbeit, Finanzen und Wirtschaft. Veraltete Rollenvorstellungen existieren ebenfalls in der digitalen Welt.</p>
    <p class="card-text">Matthias Spielkram erzählt von einem Experiment, das er mit seiner Organisation AlgorithmWatch
        durchgeführt hat: Sie
        veröffentlichten zwei Stellenanzeigen auf Facebook, in der ersten suchten sie eine:n „LKW-Fahrer:in“, in der anderen
        eine:n „Pfleger:in“. Obwohl sie nicht explizit auswählten, an wen die jeweiligen Stellenanzeigen ausgespielt werden
        sollten, wurde die „LKW-Fahrer:in“-Anzeige zu 92 Prozent Männern angezeigt und die „Pfleger:in“-Anzeige zu 96
        Prozent Frauen. „Das zeigt, dass da ein Vorurteil im System steckt. Der <b>Algorithmus </b> aus der Vergangenheit
        gelernt, welcher Beruf eher zu Männern und welcher eher zu Frauen passt“, ist sich Spielkram sicher.</p>
    <p class="card-text">Auch Google hält an traditionellen Geschlechterrollen fest, wie ein anderes Beispiel aus der Doku
        beweist: Die
        Forscherin Özlem Türeci war maßgeblich an der Entwicklung des Corona-Impfstoffs beteiligt. Gab man aber ihren Namen
        in das Suchfenster bei Google ein, wurde sie bis vor kurzem noch als „Ehefrau von Augur Sahin“ angezeigt. Bei Herrn
        Sahin wurde dagegen sein Titel als Biontech-Gründer gezeigt. Mittlerweile ist Özlem Türeci zwar mehr als eine
        Ehefrau, aber immer noch lediglich Ärztin statt Gründerin.</p>

    <h2><strong>Besonders schlimm: Mehrfachdiskriminierung in der digitalen Welt</strong></h2>

    <p class="card-text">Die Beispiele zeigen, dass die Hälfte der Weltbevölkerung aufgrund ihres Geschlechts von Algorithmen
        benachteiligt
        werden kann. Noch gravierender wird es laut der Expert:innen, wenn eine Frau zusätzlich zum Beispiel aufgrund ihrer
        Herkunft, Hautfarbe, Klasse oder sexuellen Orientierung diskriminiert wird. Im Beitrag erzählt die Unternehmerin Jen
        Martens, dass sie Instagram zur Vermarktung ihrer Beauty-Produkte nutzt. Dabei ist ihr etwas Unglaubliches
        aufgefallen: „Wenn ich Content kreiere und dabei einen Schwarzen Menschen zeige, wird der Post nicht verbreitet.“
        Deshalb muss sie dazwischen immer einen weißen Menschen posten, damit der Algorithmus wieder greift.</p>
    <p class="card-text">Auch die Mutter und Influencerin Tanja Marfo hat Diskriminierung auf Instagram erlebt – in ihrem
        Fall war es
        Body-Shaming. Als mehrgewichtige <b>Frau</b> wird sie nicht selten beschimpft und ist sich sicher, dass der Hass
        gegen sie
        vom Instagram-Algorithmus zusätzlich befeuert wird. Es habe aber auch schon Situationen gegeben, in denen der
        Algorithmus selbst fettfeindlich gewesen sei. So habe eine Freundin in einem Post „Bauchfett“ thematisieren wollen
        und dafür ihren eigenen Bauch enthüllt. Sie konnte das Bild aber nicht bei Instagram hochladen weil es „Nacktheit
        und Bauchfett“ zeige. „Also diskriminiert Instagram Bauchfett von mehrgewichtigen Menschen. Ein Waschbrettbauch
        eines Mannes darf aber gezeigt werden“, ärgert sich Marfo.</p>
    <p class="card-text">Die Expert:innen in der Doku sind sich also einig: Algorithmen folgen sexistischen und
        diskriminierenden Mustern. Man
        könnte sie auch fair programmieren. Doch das geschieht nicht. Vermutlich, weil sich mit der Norm besser Geld
        verdienen lässt – und die Norm ist nun einmal weiß, männlich und heterosexuell. Das Problem ist aber auch:
        <b>Diskriminierung</b> lässt sich nicht mal schnell reprogrammieren. Dafür müssen wir erst in der realen Welt für
        Gerechtigkeit sorgen …
    </p>
@endsection

<!--@section('title-blok')
    Female empowerment
@endsection-->
